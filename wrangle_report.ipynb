{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "---\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Gathering](#gathering)\n",
    "* [Assessing](#assessing)\n",
    "* [Cleaning](#cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "\n",
    "# Introduction\n",
    "---\n",
    "\n",
    "> The goal of this project is wrangling WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. The Twitter archive is great, but it only contains very basic tweet information. Additional gathering, then assessing and cleaning is required for \"Wow!\"-worthy analyses and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gathering'></a>\n",
    "\n",
    "# Gathering\n",
    "---\n",
    "\n",
    "\n",
    "> **Enhanced Twitter Archive** \n",
    ">\n",
    "> Provided by Udacity\n",
    "\n",
    "\n",
    "> **Image Predictions File**\n",
    ">\n",
    "> Downloaded programmatically using the Requests library and the following URL: [https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv)\n",
    "\n",
    "```python\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url, allow_redirects=True)\n",
    "with open(image_predictions_filepath, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "```\n",
    "\n",
    "> **Additional Data via the Twitter API**\n",
    ">\n",
    "> Used the tweet IDs in the WeRateDogs Twitter archive, queried the Twitter API for each tweet's JSON data using Python's Tweepy library and stored each tweet's entire set of JSON data in a file called tweet_json.txt file\n",
    "\n",
    "\n",
    "```python\n",
    "with open('twitter-credential.json') as f:\n",
    "    credentials = json.load(f)\n",
    "auth = tweepy.OAuthHandler(credentials['consumer_key'], credentials['consumer_secret'])\n",
    "auth.set_access_token(credentials['access_token'], credentials['access_token_secret'])\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "tweet_ids = df_wrd_twitter_old['tweet_id']\n",
    "statuses = []\n",
    "for tweet_id in tqdm(tweet_ids):\n",
    "    try:\n",
    "        status = api.get_status(tweet_id, tweet_mode='extended')\n",
    "        statuses.append(status._json)\n",
    "    except:\n",
    "        continue\n",
    "with open(json_filepath, 'w') as outfile:\n",
    "    for status in statuses:\n",
    "        json.dump(status, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "```\n",
    "\n",
    "> **Dog Breed Labels**\n",
    "> * Downloaded from Kaggle\n",
    "> * Did not programmatically download since the zip folder contains unnecessary files\n",
    "> * **URL**: https://www.kaggle.com/c/dog-breed-identification/data \n",
    "> * Only uses `labels.csv` in this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing'></a>\n",
    "\n",
    "# Assessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Key Points**\n",
    "> * Only original ratings (no retweets) that have images is wanted\n",
    "> * The tweets beyond August 1st, 2017 do not need to be gathered.\n",
    "> * Cleaning includes merging individual pieces of data according to the rules of tidy data\n",
    "> * The rating numerators are greater than the denominators does not need to be cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Enhanced Twitter Archive**\n",
    "> * name, doggo, floofer, pupper and puppo columns contain \"None\"\n",
    "> * name contains \"a\" as a value. May contain other nonsense name\n",
    "> * tweet information and dog information in the same table\n",
    "> * name (refers to dog name) is not very descriptive since tweet information and dog information are in the same table\n",
    "> * text (refers to status update) is not very descriptive since tweet information and dog information are in the same table\n",
    "> * All ids(tweet_id, in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id)\n",
    " have numeric data type instead of string\n",
    "> * timestamp is of string type\n",
    "> * Even though some columns have null values, it is reasonable\n",
    "> * doggo, floofer, pupper and puppo can be combined into a single column\n",
    "> * Columns may be ignored: \n",
    ">   in_reply_to_status_id, in_reply_to_user_id, source, expanded_urls\n",
    "> * Have invalid names other than 'None', eg: a, an, the, one. All starts with lowercase characters.\n",
    "> * Name column has duplicated entries\n",
    "> * There are 7 rows in df_wrd_twitter_old with wrong denominators and numerators\n",
    "> * There is 2 rows parsing time as ratings: 1) 24/7 2) 11/15/15\n",
    "> * name, doggo, pupper, puppo and floofer have \"None\" values as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Image Predictions File**\n",
    ">\n",
    "> * img_num, p1, p1_conf, p1_dog, etc. are not very descriptive\n",
    "> * Values of p1, p2, p3 have formatting issues. Some starts with uppercase characters, but others start with lowercase characters. In addition, some are separated by \"-\" while others have \"_\" as delimiter\n",
    "> * The data type of tweet_id is integer\n",
    "> * No missing values in this table\n",
    "> * There exist rows where either p1_dog, p2_dog or p3_dog is true, but predictions do not belong to dog breeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Additional Data via the Twitter API**\n",
    ">\n",
    "> * For each type of id, there are two columns for it for the same piece of information, and their data type are the same \n",
    "> * Columns may be ignored: \n",
    ">   * created_at, truncated, in_reply_to_user_id, in_reply_to_status_id_str, in_reply_to_user_id\n",
    ">   * in_reply_to_user_id_str, in_reply_to_screen_name, is_quote_status, possibly_sensitive\n",
    ">   * possibly_sensitive_appealable, lang, quoted_status_id, quoted_status_id_str, quoted_status_permalink\n",
    ">   * quoted_status, geo, coordinates, place\n",
    "> * id is of numeric type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Dog Breed Labels**\n",
    "> * There are duplicates under the breed column of df_dog_breeds\n",
    "> * Formatting issues: both \"-\" and \"_\" are used for separaters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * All Id related fields have wrong data types.\n",
    "> * timestamp has wrong data type\n",
    "> * There exist rows that rating_denominator and rating_numerator does not match text\n",
    "> * Duplicated columns for same pieces of data and same data types\n",
    "> * Some column names are not descriptive\n",
    "> * Some column values have formatting issues\n",
    "> * Some column values have duplicates\n",
    "> * There exists rows that either p1_dog, p2_dog or p3_dog is true, but predictions do not belong to dog breeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * tweet information and dog information in the same table\n",
    "> * doggo, floofer, pupper and puppo can be combined into a single column\n",
    "> * tweet information are separated into three tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleaning'></a>\n",
    "\n",
    "# Cleaning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Dog Breed Labels**\n",
    "> * Find out rows that are duplicated, get their indices and remove by row indices\n",
    "> * Fix formatting issues in the breed column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Enhanced Twitter Archive**\n",
    "> * Filter out retweets by removing the ones with retweeted_status_id\n",
    "> * Drop unnessary columns\n",
    "> * Update and Remove rows with inaccurate ratings\n",
    ">   * Get all texts where denominator and numerator are wrong\n",
    ">   * Get all rows in the dataframe by matching texts\n",
    ">   * Remove these rows in the dataframe by indices\n",
    "> * Change data types\n",
    ">   * Change data type of tweet_id to object(string) using `.astype(str)`\n",
    "> * Change data type of timestamp to timestamp using `pd.to_datetime` and `utc=True`\n",
    "> * Filter out tweets beyond August 1st, 2017\n",
    ">    * Create a new dataframe with shape(the number of rows in df_wrd_twitter, 1). \n",
    ">    * Fill it with value = '2017-08-01'\n",
    ">    * Convert both series using code like `pd.to_datetime(time_df['timestamp'], utc=True)`\n",
    ">    * Compare these two series, get the rows with timestamp higher than 2017-08-01, remove by row indices\n",
    "> * Rename columns using `df.rename`\n",
    ">   * name -> dog_name\n",
    ">   * text -> status_update\n",
    "> * Remove rows with invalid names\n",
    ">   * Find rows containing invalid names: \"None\" and words starting with lowercase characters\n",
    ">   * Delete rows using row indices\n",
    "> * Combine four dog \"states\" into a single column\n",
    ">   * Find out indices of row with a specific dog state eg. 'doggo'\n",
    ">   * Set the \"dog_state\" of these rows to a value which represents this dog state\n",
    ">   * Same action for all states\n",
    "> * Remove doggo, floofer, pupper, puppo columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Image Predictions File**\n",
    "> * Change data type of tweet_id to object\n",
    "> * Fix formatting issues of p1, p2 and p3. Final format: starts with lowercase characters and seperated by \"_\"\n",
    "> * For rows where either p1_dog, p2_dog or p3_dog is true, but predictions do not belong to dog breeds, remove these rows\n",
    "> * Rename p1, p2, p3, p1_conf, p2_conf, p3_conf, p1_dog, p2_dog, p3_dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Additional Data via the Twitter API**\n",
    "> * Drop unnecessary columns\n",
    "> * Change the data type of id to string\n",
    "> * Filter out retweets by removing rows with non-null retweeted_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
