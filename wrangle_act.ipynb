{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import tweepy\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "DATA_READY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Logging Configuration\n",
    "'''\n",
    "\n",
    "logs_dir = \"./logs\"\n",
    "\n",
    "log_filepath = os.path.join(logs_dir, 'df_wrd_error.log')\n",
    "\n",
    "logging.basicConfig(filename=log_filepath, filemode='w', format='%(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "INFO = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "# Table of Contents\n",
    "---\n",
    "\n",
    "* [I. Gathering](#gathering)\n",
    "* [II. Assessing](#assessing)\n",
    "* [III. Cleaning](#cleaning)\n",
    "* [IV. Analyzing](#analyzing)\n",
    "* [III. Visualizing](#visualizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gathering'></a>\n",
    "# I. Gathering Data \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. WeRateDogs Twitter Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrd_data_filepath = 'twitter-archive-enhanced.csv'\n",
    "\n",
    "df_wrd_twitter_old = pd.read_csv(os.path.join(data_dir, wrd_data_filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Tweet Image Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_filepath = os.path.join(data_dir, 'image-predictions.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_READY:\n",
    "\n",
    "    url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "\n",
    "    with open(image_predictions_filepath, 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions_old = pd.read_csv(image_predictions_filepath, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Any Additional Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Via Twitter API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filepath = os.path.join(data_dir, \"tweet_json.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_READY:\n",
    "\n",
    "    with open('twitter-credential.json') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    auth = tweepy.OAuthHandler(credentials['consumer_key'], credentials['consumer_secret'])\n",
    "\n",
    "    auth.set_access_token(credentials['access_token'], credentials['access_token_secret'])\n",
    "\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "    tweet_ids = df_wrd_twitter_old['tweet_id']\n",
    "\n",
    "    statuses = []\n",
    "\n",
    "    for tweet_id in tqdm(tweet_ids):\n",
    "\n",
    "        try:\n",
    "\n",
    "            status = api.get_status(tweet_id, tweet_mode='extended')\n",
    "\n",
    "            statuses.append(status._json)\n",
    "\n",
    "        except:\n",
    "\n",
    "            continue\n",
    "\n",
    "    with open(json_filepath, 'w') as outfile:\n",
    "        for status in statuses:\n",
    "            json.dump(status, outfile)\n",
    "            outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_json_old = pd.read_json(json_filepath, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Via Kaggle** [For all available dog breeds]\n",
    "\n",
    "Reference: \n",
    "    [https://www.kaggle.com/c/dog-breed-identification/data](https://www.kaggle.com/c/dog-breed-identification/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dog_breeds_old = pd.read_csv(os.path.join(data_dir, \"labels.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing'></a>\n",
    "# II. Assessing Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUncomment to view data\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Uncomment to view data\n",
    "'''\n",
    "\n",
    "# df_wrd_twitter_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Summary**\n",
    "> * name, doggo, floofer, pupper and puppo columns contain \"None\"\n",
    "> * name contains \"a\" as a value. May contain other nonsense name\n",
    "> * tweet information and dog information in the same table\n",
    "> * name (refers to dog name) is not very descriptive since tweet information and dog information are in the same table\n",
    "> * text (refers to status update) is not very descriptive since tweet information and dog information are in the same table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUncomment to view data\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Uncomment to view data\n",
    "'''\n",
    "\n",
    "# df_image_predictions_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Summary**\n",
    "> * img_num, p1, p1_conf, p1_dog, etc. are not very descriptive\n",
    "> * Values of p1, p2, p3 have formatting issues. Some starts with uppercase characters, but others start with lowercase characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUncomment to view data\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Uncomment to view data\n",
    "'''\n",
    "\n",
    "# df_tweet_json_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Summary**\n",
    "> * For each type of id, there are two columns for it for the same piece of information except that their data types are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUncomment to view data\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Uncomment to view data\n",
    "'''\n",
    "\n",
    "# df_dog_breeds_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2356 non-null   int64  \n",
      " 1   in_reply_to_status_id       78 non-null     float64\n",
      " 2   in_reply_to_user_id         78 non-null     float64\n",
      " 3   timestamp                   2356 non-null   object \n",
      " 4   source                      2356 non-null   object \n",
      " 5   text                        2356 non-null   object \n",
      " 6   retweeted_status_id         181 non-null    float64\n",
      " 7   retweeted_status_user_id    181 non-null    float64\n",
      " 8   retweeted_status_timestamp  181 non-null    object \n",
      " 9   expanded_urls               2297 non-null   object \n",
      " 10  rating_numerator            2356 non-null   int64  \n",
      " 11  rating_denominator          2356 non-null   int64  \n",
      " 12  name                        2356 non-null   object \n",
      " 13  doggo                       2356 non-null   object \n",
      " 14  floofer                     2356 non-null   object \n",
      " 15  pupper                      2356 non-null   object \n",
      " 16  puppo                       2356 non-null   object \n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_wrd_twitter_old.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Summary**\n",
    "> * All ids(tweet_id, in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id)\n",
    " have numeric data type instead of string\n",
    "> * timestamp is of string type\n",
    "> * Even though some columns have null values, it is reasonable\n",
    "> * doggo, floofer, pupper and puppo can be combined into a single column\n",
    "> * Columns may be ignored: \n",
    ">   in_reply_to_status_id, in_reply_to_user_id, source, expanded_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075 entries, 0 to 2074\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   tweet_id  2075 non-null   int64  \n",
      " 1   jpg_url   2075 non-null   object \n",
      " 2   img_num   2075 non-null   int64  \n",
      " 3   p1        2075 non-null   object \n",
      " 4   p1_conf   2075 non-null   float64\n",
      " 5   p1_dog    2075 non-null   bool   \n",
      " 6   p2        2075 non-null   object \n",
      " 7   p2_conf   2075 non-null   float64\n",
      " 8   p2_dog    2075 non-null   bool   \n",
      " 9   p3        2075 non-null   object \n",
      " 10  p3_conf   2075 non-null   float64\n",
      " 11  p3_dog    2075 non-null   bool   \n",
      "dtypes: bool(3), float64(3), int64(2), object(4)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_image_predictions_old.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Summary**\n",
    "> * The data type of tweet_id is integer\n",
    "> * No missing values in this table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2331 entries, 0 to 2330\n",
      "Data columns (total 32 columns):\n",
      " #   Column                         Non-Null Count  Dtype              \n",
      "---  ------                         --------------  -----              \n",
      " 0   created_at                     2331 non-null   datetime64[ns, UTC]\n",
      " 1   id                             2331 non-null   int64              \n",
      " 2   id_str                         2331 non-null   int64              \n",
      " 3   full_text                      2331 non-null   object             \n",
      " 4   truncated                      2331 non-null   bool               \n",
      " 5   display_text_range             2331 non-null   object             \n",
      " 6   entities                       2331 non-null   object             \n",
      " 7   extended_entities              2059 non-null   object             \n",
      " 8   source                         2331 non-null   object             \n",
      " 9   in_reply_to_status_id          77 non-null     float64            \n",
      " 10  in_reply_to_status_id_str      77 non-null     float64            \n",
      " 11  in_reply_to_user_id            77 non-null     float64            \n",
      " 12  in_reply_to_user_id_str        77 non-null     float64            \n",
      " 13  in_reply_to_screen_name        77 non-null     object             \n",
      " 14  user                           2331 non-null   object             \n",
      " 15  geo                            0 non-null      float64            \n",
      " 16  coordinates                    0 non-null      float64            \n",
      " 17  place                          1 non-null      object             \n",
      " 18  contributors                   0 non-null      float64            \n",
      " 19  is_quote_status                2331 non-null   bool               \n",
      " 20  retweet_count                  2331 non-null   int64              \n",
      " 21  favorite_count                 2331 non-null   int64              \n",
      " 22  favorited                      2331 non-null   bool               \n",
      " 23  retweeted                      2331 non-null   bool               \n",
      " 24  possibly_sensitive             2196 non-null   float64            \n",
      " 25  possibly_sensitive_appealable  2196 non-null   float64            \n",
      " 26  lang                           2331 non-null   object             \n",
      " 27  retweeted_status               163 non-null    object             \n",
      " 28  quoted_status_id               26 non-null     float64            \n",
      " 29  quoted_status_id_str           26 non-null     float64            \n",
      " 30  quoted_status_permalink        26 non-null     object             \n",
      " 31  quoted_status                  24 non-null     object             \n",
      "dtypes: bool(4), datetime64[ns, UTC](1), float64(11), int64(4), object(12)\n",
      "memory usage: 519.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_tweet_json_old.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Summary**\n",
    "> * Columns may be ignored: \n",
    ">   * created_at, truncated, in_reply_to_user_id, in_reply_to_status_id_str, in_reply_to_user_id\n",
    ">   * in_reply_to_user_id_str, in_reply_to_screen_name, is_quote_status, possibly_sensitive\n",
    ">   * possibly_sensitive_appealable, lang, quoted_status_id, quoted_status_id_str, quoted_status_permalink\n",
    ">   * quoted_status, geo, coordinates, place\n",
    "> * id is of numeric type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      10222 non-null  object\n",
      " 1   breed   10222 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 159.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dog_breeds_old.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ****************************** Further Investigation On Data  ******************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrd_twitter_old.duplicated(['tweet_id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1399"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrd_twitter_old.duplicated(['name']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INFO:\n",
    "    print(df_wrd_twitter_old['name'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Summary**\n",
    "> * Have invalid names other than 'None', eg: a, an, the, one. All starts with lowercase characters.\n",
    "> * Name column has duplicated entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of true positive ratings:  2333\n",
      "Number of wrong ratings:  7\n",
      "Please check for logs for wrong ratings\n"
     ]
    }
   ],
   "source": [
    "p = re.compile('[0-9]+/10')\n",
    "p_invalid = re.compile('[0-9]+/[0-9]+/[0-9]+')\n",
    "\n",
    "bad_count = 0\n",
    "none_count = 0\n",
    "good_count = 0\n",
    "\n",
    "\n",
    "for text, denominator, numerator in zip(df_wrd_twitter_old['text'].values, df_wrd_twitter_old['rating_denominator'].values, df_wrd_twitter_old['rating_numerator'].values):\n",
    "    result = p.search(text)\n",
    "    if result is not None and denominator != 10: # when denominators and numerators are wrong\n",
    "        if INFO:\n",
    "            message = \"{} {} {} ************************ {}\".format(result.group(), numerator, denominator, text)\n",
    "            logging.error(message)\n",
    "            logging.error(\"\\n\")\n",
    "        bad_count += 1\n",
    "    elif result is None and p_invalid.search(text) == None:\n",
    "#         print(numerator, denominator, \"~~~~~~~~~~~~~~~~~~~~~~~\", text)\n",
    "#         print()\n",
    "        none_count += 1\n",
    "    elif result is not None and denominator == 10:\n",
    "        good_count += 1\n",
    "    elif p_invalid.search(text) != None: # when parsing date as ratings\n",
    "        if INFO:\n",
    "            message = \"{} {} ************************ {}\".format(numerator, denominator, text)\n",
    "            logging.error(message)\n",
    "            logging.error(\"\\n\")\n",
    "\n",
    "print(\"Number of true positive ratings: \", good_count)\n",
    "print(\"Number of wrong ratings: \", bad_count)\n",
    "print(\"Please check for logs for wrong ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>rating_numerator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>@jonnysun @Lin_Manuel ok jomny I know you're e...</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>RT @dog_rates: After so many requests, this is...</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>After so many requests, this is Bretagne. She ...</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>Happy 4/20 from the squad! 13/10 for all https...</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>This is Bluebert. He just saw that both #Final...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>This is Darrel. He just robbed a 7/11 and is i...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>This is an Albanian 3 1/2 legged  Episcopalian...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  rating_denominator  \\\n",
       "313   @jonnysun @Lin_Manuel ok jomny I know you're e...                   0   \n",
       "784   RT @dog_rates: After so many requests, this is...                  11   \n",
       "1068  After so many requests, this is Bretagne. She ...                  11   \n",
       "1165  Happy 4/20 from the squad! 13/10 for all https...                  20   \n",
       "1202  This is Bluebert. He just saw that both #Final...                  50   \n",
       "1662  This is Darrel. He just robbed a 7/11 and is i...                  11   \n",
       "2335  This is an Albanian 3 1/2 legged  Episcopalian...                   2   \n",
       "\n",
       "      rating_numerator  \n",
       "313                960  \n",
       "784                  9  \n",
       "1068                 9  \n",
       "1165                 4  \n",
       "1202                50  \n",
       "1662                 7  \n",
       "2335                 1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_remove = []\n",
    "\n",
    "for text, denominator, numerator in zip(\n",
    "    df_wrd_twitter_old['text'].values, \n",
    "    df_wrd_twitter_old['rating_denominator'].values, \n",
    "    df_wrd_twitter_old['rating_numerator'].values):\n",
    "    \n",
    "    result = p.search(text)\n",
    "    \n",
    "    if result is not None and denominator != 10:\n",
    "        text_to_remove.append(text)\n",
    "        \n",
    "df_wrd_twitter_old[df_wrd_twitter_old.text.isin(text_to_remove)][\n",
    "    ['text', 'rating_denominator', 'rating_numerator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Summary**\n",
    "> * There are 7 rows in df_wrd_twitter_old with wrong denominators and numerators\n",
    "> * There is 2 rows parsing time as ratings: 1) 24/7 2) 11/15/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                         0\n",
       "in_reply_to_status_id            0\n",
       "in_reply_to_user_id              0\n",
       "timestamp                        0\n",
       "source                           0\n",
       "text                             0\n",
       "retweeted_status_id              0\n",
       "retweeted_status_user_id         0\n",
       "retweeted_status_timestamp       0\n",
       "expanded_urls                    0\n",
       "rating_numerator                 0\n",
       "rating_denominator               0\n",
       "name                           745\n",
       "doggo                         2259\n",
       "floofer                       2346\n",
       "pupper                        2099\n",
       "puppo                         2326\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrd_twitter_old.isin([\"None\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Summary**\n",
    "> * name, doggo, pupper, puppo and floofer have \"None\" values as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_image_predictions_old.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nHave TypeError after executing the above statement\\n- TypeError: unhashable type: 'list'\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_tweet_json_old.duplicated().sum()\n",
    "\n",
    "'''\n",
    "Have TypeError after executing the above statement\n",
    "- TypeError: unhashable type: 'list'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10102"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dog_breeds_old.duplicated(['breed']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INFO:\n",
    "    print(df_dog_breeds_old['breed'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Summary**\n",
    "> * There are duplicates under the breed column of df_dog_breeds\n",
    "> * Formatting issues: both \"-\" and \"_\" are used for separaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleaning'></a>\n",
    "# III. Cleaning Data \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrd_twitter = df_wrd_twitter_old.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions = df_image_predictions_old.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_json = df_tweet_json_old.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dog_breeds = df_dog_breeds_old.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dbl'></a>\n",
    "\n",
    "### Dog Breed Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Find out rows that are duplicated, get their indices and remove by row indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_row_indices = df_dog_breeds[df_dog_breeds.duplicated(['breed'])].index\n",
    "\n",
    "if DEBUG:\n",
    "    print(duplicated_row_indices.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dog_breeds.drop(duplicated_row_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(duplicated_row_indices.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fix formatting issues in the breed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_dog_breeds['breed'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dog_breeds['breed'] = df_dog_breeds['breed'].str.replace(\"-\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_dog_breeds['breed'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='eta'></a>\n",
    "\n",
    "### Enhanced Twitter Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Filter out retweets by removing the ones with retweeted_status_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_with_retweets = df_wrd_twitter[df_wrd_twitter['retweeted_status_id'].notnull()].index\n",
    "\n",
    "df_wrd_twitter.drop(indices_with_retweets, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_wrd_twitter['retweeted_status_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Drop unnessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_columns = [\n",
    "    'in_reply_to_status_id', \n",
    "    'in_reply_to_user_id',\n",
    "    'source',\n",
    "    'retweeted_status_id',\n",
    "    'retweeted_status_user_id',\n",
    "    'retweeted_status_timestamp',\n",
    "    'expanded_urls']\n",
    "\n",
    "df_wrd_twitter.drop(unnecessary_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_wrd_twitter.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Update and Remove rows with inaccurate ratings\n",
    "> * Get all texts where denominator and numerator are wrong\n",
    "> * Get all rows in the dataframe by matching texts\n",
    "> * Remove these rows in the dataframe by indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_to_update = []\n",
    "ratings_to_remove = []\n",
    "\n",
    "for text, denominator, numerator in zip(\n",
    "    df_wrd_twitter['text'].values, \n",
    "    df_wrd_twitter['rating_denominator'].values, \n",
    "    df_wrd_twitter['rating_numerator'].values):\n",
    "    \n",
    "    result = p.search(text)\n",
    "    \n",
    "    if result is not None and denominator != 10:\n",
    "        ratings_to_update.append(text)\n",
    "    elif text.find('24/7') != -1 or text.find('11/15/15') != -1:\n",
    "        ratings_to_remove.append(text)\n",
    "        \n",
    "if DEBUG:\n",
    "    print(\"# of rows to update ratings: \", len(ratings_to_update))\n",
    "    print(\"# of rows to remove: \", len(ratings_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrd_twitter['text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, denominator, numerator in zip(\n",
    "    df_wrd_twitter['text'].values, \n",
    "    df_wrd_twitter['rating_denominator'].values, \n",
    "    df_wrd_twitter['rating_numerator'].values):\n",
    "    \n",
    "    result = p.search(text)\n",
    "    \n",
    "    if result is not None and denominator != 10:\n",
    "        \n",
    "        # since text is unique\n",
    "        index = df_wrd_twitter[df_wrd_twitter['text'] == text].index[0]\n",
    "        \n",
    "        ratings = result.group(0).split(\"/\")\n",
    "        \n",
    "        df_wrd_twitter.at[index, 'rating_denominator'] = 10\n",
    "        df_wrd_twitter.at[index, 'rating_numerator'] = ratings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_with_wrong_ratings = df_wrd_twitter[df_wrd_twitter.text.isin(ratings_to_remove)].index\n",
    "\n",
    "df_wrd_twitter.drop(indices_with_wrong_ratings, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    \n",
    "    ratings_to_update = []\n",
    "    ratings_to_remove = []\n",
    "\n",
    "    for text, denominator, numerator in zip(\n",
    "        df_wrd_twitter['text'].values, \n",
    "        df_wrd_twitter['rating_denominator'].values, \n",
    "        df_wrd_twitter['rating_numerator'].values):\n",
    "\n",
    "        result = p.search(text)\n",
    "\n",
    "        if result is not None and denominator != 10:\n",
    "            ratings_to_update.append(text)\n",
    "        elif text.find('24/7') != -1 or text.find('11/15/15') != -1:\n",
    "            ratings_to_remove.append(text)\n",
    "\n",
    "    print(\"# of rows to update ratings: \", len(ratings_to_update))\n",
    "    print(\"# of rows to remove: \", len(ratings_to_remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Change data types\n",
    "> * Change data type of tweet_id to object(string) using `.astype(str)`\n",
    "> * Change data type of timestamp to timestamp using `pd.to_datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_wrd_twitter['tweet_id'].dtype, df_wrd_twitter['timestamp'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrd_twitter['tweet_id'] = df_wrd_twitter['tweet_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrd_twitter['timestamp'] = pd.to_datetime(df_wrd_twitter['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_wrd_twitter['tweet_id'].dtype, df_wrd_twitter['timestamp'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rename columns using `df.rename`\n",
    "> * name -> dog_name\n",
    "> * text -> status_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    'text': 'status_update', \n",
    "    'name': 'dog_name'\n",
    "}\n",
    "\n",
    "df_wrd_twitter.rename(columns=columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_wrd_twitter.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Change all invalid names to None not \"None\" \n",
    "> * Find rows containing invalid names: \"None\" and words starting with lowercase characters\n",
    "> * Delete rows using row indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_wrd_twitter.query(\"dog_name.str.islower() or dog_name == 'None'\").index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_with_invalid_names = df_wrd_twitter.query(\"dog_name.str.islower() or dog_name == 'None'\").index\n",
    "\n",
    "df_wrd_twitter.drop(indices_with_invalid_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_wrd_twitter.query(\"dog_name.str.islower() or dog_name == 'None'\").index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1390 entries, 0 to 2325\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype              \n",
      "---  ------              --------------  -----              \n",
      " 0   tweet_id            1390 non-null   object             \n",
      " 1   timestamp           1390 non-null   datetime64[ns, UTC]\n",
      " 2   status_update       1390 non-null   object             \n",
      " 3   rating_numerator    1390 non-null   int64              \n",
      " 4   rating_denominator  1390 non-null   int64              \n",
      " 5   dog_name            1390 non-null   object             \n",
      " 6   doggo               1390 non-null   object             \n",
      " 7   floofer             1390 non-null   object             \n",
      " 8   pupper              1390 non-null   object             \n",
      " 9   puppo               1390 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(7)\n",
      "memory usage: 119.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_wrd_twitter.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='ipf'></a>\n",
    "\n",
    "### Image Predictions File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Change data type of tweet_id to object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_image_predictions['tweet_id'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions['tweet_id'] = df_image_predictions['tweet_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_image_predictions['tweet_id'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fix formatting issues of p1, p2 and p3. Final format: starts with lowercase characters and seperated by \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions['p1'] = df_image_predictions['p1'].str.lower()\n",
    "df_image_predictions['p1'] = df_image_predictions['p1'].str.replace(\"-\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions['p2'] = df_image_predictions['p2'].str.lower()\n",
    "df_image_predictions['p2'] = df_image_predictions['p2'].str.replace(\"-\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions['p3'] = df_image_predictions['p3'].str.lower()\n",
    "df_image_predictions['p3'] = df_image_predictions['p3'].str.replace(\"-\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_image_predictions['p1'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For rows where either p1_dog, p2_dog or p3_dog is true, but predictions do not belong to dog breeds\n",
    "> * Remove these rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    \n",
    "    error_count_1 = df_image_predictions[~df_image_predictions.p1.isin(df_dog_breeds['breed'])]['p1_dog'].sum()\n",
    "    error_count_2 = df_image_predictions[~df_image_predictions.p2.isin(df_dog_breeds['breed'])]['p2_dog'].sum()\n",
    "    error_count_3 = df_image_predictions[~df_image_predictions.p3.isin(df_dog_breeds['breed'])]['p3_dog'].sum()\n",
    "\n",
    "    print(error_count_1, error_count_2, error_count_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_indices_to_remove = \\\n",
    "    df_image_predictions[~df_image_predictions.p1.isin(df_dog_breeds['breed'])].query(\"p1_dog == True\").index\n",
    "df_image_predictions.drop(p1_indices_to_remove, inplace=True)\n",
    "    \n",
    "p2_indices_to_remove = \\\n",
    "    df_image_predictions[~df_image_predictions.p2.isin(df_dog_breeds['breed'])].query(\"p2_dog == True\").index\n",
    "df_image_predictions.drop(p2_indices_to_remove, inplace=True)\n",
    "    \n",
    "p3_indices_to_remove = \\\n",
    "    df_image_predictions[~df_image_predictions.p3.isin(df_dog_breeds['breed'])].query(\"p3_dog == True\").index\n",
    "df_image_predictions.drop(p3_indices_to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    \n",
    "    error_count_1 = df_image_predictions[~df_image_predictions.p1.isin(df_dog_breeds['breed'])]['p1_dog'].sum()\n",
    "    error_count_2 = df_image_predictions[~df_image_predictions.p2.isin(df_dog_breeds['breed'])]['p2_dog'].sum()\n",
    "    error_count_3 = df_image_predictions[~df_image_predictions.p3.isin(df_dog_breeds['breed'])]['p3_dog'].sum()\n",
    "\n",
    "    print(error_count_1, error_count_2, error_count_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rename p1, p2, p3, p1_conf, p2_conf, p3_conf, p1_dog, p2_dog, p3_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_image_predictions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map = {\n",
    "    'p1': 'prediction_1',\n",
    "    'p1_conf': 'prediction_1_confidence',\n",
    "    'p1_dog': 'is_prediction_1_dog_breed',\n",
    "    'p2': 'prediction_2',\n",
    "    'p2_conf': 'prediction_2_confidence',\n",
    "    'p2_dog': 'is_prediction_2_dog_breed',\n",
    "    'p3': 'prediction_3',\n",
    "    'p3_conf': 'prediction_3_confidence',\n",
    "    'p3_dog': 'is_prediction_3_dog_breed'\n",
    "}\n",
    "\n",
    "df_image_predictions.rename(columns=column_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(df_image_predictions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2053 entries, 0 to 2074\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   tweet_id                   2053 non-null   object \n",
      " 1   jpg_url                    2053 non-null   object \n",
      " 2   img_num                    2053 non-null   int64  \n",
      " 3   prediction_1               2053 non-null   object \n",
      " 4   prediction_1_confidence    2053 non-null   float64\n",
      " 5   is_prediction_1_dog_breed  2053 non-null   bool   \n",
      " 6   prediction_2               2053 non-null   object \n",
      " 7   prediction_2_confidence    2053 non-null   float64\n",
      " 8   is_prediction_2_dog_breed  2053 non-null   bool   \n",
      " 9   prediction_3               2053 non-null   object \n",
      " 10  prediction_3_confidence    2053 non-null   float64\n",
      " 11  is_prediction_3_dog_breed  2053 non-null   bool   \n",
      "dtypes: bool(3), float64(3), int64(1), object(5)\n",
      "memory usage: 166.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_image_predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='adta'></a>\n",
    "\n",
    "### Additional Data via the Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * Drop unnecessary columns\n",
    "> * Change the data type of id to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_columns = [\n",
    "    'created_at', \n",
    "    'id_str',\n",
    "    'full_text',\n",
    "    'truncated',\n",
    "    'display_text_range',\n",
    "    'entities',\n",
    "    'extended_entities',\n",
    "    'source',\n",
    "    'in_reply_to_status_id',\n",
    "    'in_reply_to_status_id_str',\n",
    "    'in_reply_to_user_id',\n",
    "    'in_reply_to_user_id_str',\n",
    "    'in_reply_to_screen_name',\n",
    "    'user',\n",
    "    'geo',\n",
    "    'coordinates',\n",
    "    'place',\n",
    "    'contributors',\n",
    "    'is_quote_status',\n",
    "    'possibly_sensitive',\n",
    "    'possibly_sensitive_appealable',\n",
    "    'lang',\n",
    "    'quoted_status_id',\n",
    "    'quoted_status_id_str',\n",
    "    'quoted_status_permalink',\n",
    "    'quoted_status']\n",
    "\n",
    "df_tweet_json.drop(unnecessary_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_json['id'] = df_tweet_json['id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Filter out retweets by removing rows with non-null retweeted_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_json.drop(df_tweet_json[df_tweet_json['retweeted_status'].notnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2168 entries, 0 to 2330\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                2168 non-null   object\n",
      " 1   retweet_count     2168 non-null   int64 \n",
      " 2   favorite_count    2168 non-null   int64 \n",
      " 3   favorited         2168 non-null   bool  \n",
      " 4   retweeted         2168 non-null   bool  \n",
      " 5   retweeted_status  0 non-null      object\n",
      "dtypes: bool(2), int64(2), object(2)\n",
      "memory usage: 88.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_tweet_json.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
